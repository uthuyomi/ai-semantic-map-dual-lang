# ==============================================================
# ğŸŒ AI Semantic Map â€” Dual-Language Visualization (JA & EN)
# ==============================================================
# ğŸ·ï¸ Overview / æ¦‚è¦
# --------------------------------------------------------------
# This script generates two semantic maps from a single question.
# It automatically translates the question (JA â†” EN),
# then visualizes how AI perceives the same concept in both languages.
#
# æ—¥æœ¬èªã¾ãŸã¯è‹±èªã®è³ªå•ã‚’1ã¤å…¥åŠ›ã™ã‚‹ã¨ã€
# è‡ªå‹•çš„ã«ã‚‚ã†ä¸€æ–¹ã®è¨€èªã«ç¿»è¨³ã—ã€
# ã€Œæ—¥æœ¬èªç‰ˆã€ã¨ã€Œè‹±èªç‰ˆã€ã®2ã¤ã®æ„å‘³ç©ºé–“ãƒãƒƒãƒ—ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
# --------------------------------------------------------------
# Author : å®‰å´ æµ·æ˜Ÿ (Kaisei Yasuzaki)
# Model  : GPT-4o
# Version: 4.0 (2025)
# ==============================================================

from openai import OpenAI
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
import numpy as np
import matplotlib.font_manager as fm
import textwrap, re

# ==============================================================
# âš™ï¸ 1. Configuration / åŸºæœ¬è¨­å®š
# ==============================================================
client = OpenAI(api_key="")  # â† å„è‡ªã®APIã‚­ãƒ¼ã«å¤‰æ›´

num_samples = 10  # Responses per language / è¨€èªã”ã¨ã®ã‚µãƒ³ãƒ—ãƒ«æ•°

font_path_ja = "C:/Windows/Fonts/meiryo.ttc"  # Meiryo for Japanese
font_en = "Arial"  # Fallback for English
plt.rcParams["axes.unicode_minus"] = False


# ==============================================================
# ğŸ§  2. Core Function â€” Generate One Semantic Map per Language
# ==============================================================
def generate_semantic_map(question, lang="ja"):
    """
    Generate a semantic visualization for one language.
    1è¨€èªåˆ†ã®æ„å‘³ç©ºé–“ãƒãƒƒãƒ—ã‚’ç”Ÿæˆã€‚
    """

    # ---------- Theme & Font Settings / ãƒ†ãƒ¼ãƒã¨ãƒ•ã‚©ãƒ³ãƒˆ ----------
    if lang == "ja":
        color_theme = plt.cm.Blues
        lang_label = "æ—¥æœ¬èªç‰ˆ"
        title_color = "#3fa9f5"
        fm.fontManager.addfont(font_path_ja)
        plt.rcParams["font.family"] = fm.FontProperties(fname=font_path_ja).get_name()
        sep = "ãƒ»"
    else:
        color_theme = plt.cm.Oranges
        lang_label = "English Version"
        title_color = "#ffa600"
        plt.rcParams["font.family"] = font_en
        sep = " / "

    bg_color = "#0d1117"

    # ==============================================================
    # ğŸ§© Step 1: Collect AI Responses / å¿œç­”åé›†
    # ==============================================================
    responses = []
    for i in range(num_samples):
        res = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": question}],
        )
        text = res.choices[0].message.content.strip().replace("\n", " ")
        responses.append({"No": i + 1, "Output": text})
    df = pd.DataFrame(responses)

    # ==============================================================
    # ğŸ§® Step 2: TF-IDF â†’ PCA â†’ KMeans / ãƒ™ã‚¯ãƒˆãƒ«åŒ–ãƒ»æ¬¡å…ƒå‰Šæ¸›ãƒ»ã‚¯ãƒ©ã‚¹ã‚¿åŒ–
    # ==============================================================
    vectorizer = TfidfVectorizer()
    vectors = vectorizer.fit_transform(df["Output"])
    pca = PCA(n_components=3)
    points = pca.fit_transform(vectors.toarray())

    kmeans = KMeans(n_clusters=3, random_state=42, n_init="auto")
    labels = kmeans.fit_predict(vectors)
    df["Cluster"] = labels

    # ---------- Extract Cluster Labels / ã‚¯ãƒ©ã‚¹ã‚¿ä»£è¡¨èª ----------
    terms = np.array(vectorizer.get_feature_names_out())
    order_centroids = kmeans.cluster_centers_.argsort()[:, ::-1]
    cluster_labels = [
        sep.join(terms[order_centroids[i, :3]]) for i in range(len(order_centroids))
    ]

    # ==============================================================
    # ğŸ§© Step 3: Summary Generation / è¦ç´„ç”Ÿæˆ
    # ==============================================================
    if lang == "ja":
        summary_prompt = f"""
        ä»¥ä¸‹ã¯AIãŒã€Œ{question}ã€ã¨ã„ã†è³ªå•ã«å¯¾ã—ã¦å‡ºåŠ›ã—ãŸå›ç­”ç¾¤ã§ã™ã€‚
        ã“ã‚Œã‚‰ã‹ã‚‰AIãŒã“ã®æ¦‚å¿µã‚’ã©ã†æ‰ãˆã¦ã„ã‚‹ã‹ã‚’ã€
        â‘ å…±é€šç‚¹ã€€â‘¡ç›¸é•ç‚¹ã€€â‘¢å…¨ä½“ã®å‚¾å‘
        ã®3ç‚¹ã§è¦ç´„ã—ã¦ãã ã•ã„ã€‚
        ã€å›ç­”ç¾¤ã€‘
        {chr(10).join(df['Output'].tolist())}
        """
    else:
        summary_prompt = f"""
        Below are AI responses to the question: "{question}".
        Summarize how AI perceives this concept in three parts:
        â‘  Common traits, â‘¡ Differences, â‘¢ Overall tendencies.
        [Responses]
        {chr(10).join(df['Output'].tolist())}
        """

    summary_res = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": summary_prompt}],
    )
    summary_text = summary_res.choices[0].message.content.strip()

    # ==============================================================
    # ğŸ¨ Step 4: Visualization / å¯è¦–åŒ–
    # ==============================================================
    fig = plt.figure(figsize=(13, 8), facecolor=bg_color)
    ax3d = fig.add_subplot(2, 2, 1, projection="3d", facecolor=bg_color)
    ax_pie = fig.add_subplot(2, 2, 2, facecolor=bg_color)
    ax_txt = fig.add_subplot(2, 1, 2, facecolor=bg_color)

    colors = color_theme(np.linspace(0.5, 1, num_samples))

    # ---------- Scatter Plot / æ•£å¸ƒå›³ ----------
    for i, row in df.iterrows():
        ax3d.scatter(
            points[i, 0], points[i, 1], points[i, 2],
            c=[colors[i % num_samples]], s=90, edgecolors="white",
            linewidths=0.6, alpha=0.85, marker="o"
        )
        ax3d.text(
            points[i, 0], points[i, 1], points[i, 2],
            str(row["No"]), fontsize=8, color="white", ha="center"
        )

    ax3d.set_title("AI Semantic Space", color="white", fontsize=12)
    ax3d.set_xlabel("Axis 1", color="white")
    ax3d.set_ylabel("Axis 2", color="white")
    ax3d.set_zlabel("Axis 3", color="white")
    ax3d.grid(False)
    ax3d.tick_params(colors="gray")

    # ---------- Cluster Pie / ã‚¯ãƒ©ã‚¹ã‚¿åˆ†å¸ƒ ----------
    unique, counts = np.unique(labels, return_counts=True)
    wrapped_labels = [
        "\n".join(textwrap.wrap(f"{cluster_labels[i]} ({counts[i]/len(labels)*100:.1f}%)", width=20))
        for i in unique
    ]
    ax_pie.pie(
        counts,
        labels=wrapped_labels,
        colors=color_theme(np.linspace(0.2, 1, len(unique))),
        textprops={"fontsize": 9, "color": "white"},
        wedgeprops={"edgecolor": "white", "linewidth": 0.6},
    )
    ax_pie.set_title("Cluster Distribution", color="white", fontsize=12)

    # ---------- Summary Box / è¦ç´„ãƒ†ã‚­ã‚¹ãƒˆ ----------
    ax_txt.axis("off")
    sections = re.split(r"(?=â‘ |â‘¡|â‘¢)", summary_text)
    formatted_sections = []
    for sec in sections:
        sec = sec.strip()
        if not sec:
            continue
        wrapped = textwrap.fill(sec, width=85)
        formatted_sections.append(wrapped)
    formatted_text = "\n\n".join(formatted_sections)

    ax_txt.text(
        0.02, 0.98, formatted_text,
        fontsize=10, color="white", va="top", ha="left", linespacing=1.6,
        bbox=dict(boxstyle="round,pad=0.6", fc="#111", ec="white", alpha=0.15)
    )

    summary_title = "ğŸ§© AIè‡ªå·±è¦ç´„" if lang == "ja" else "ğŸ§© AI Self-Summary"
    ax_txt.set_title(summary_title, color="white", loc="left", fontsize=13, pad=12)

    # ---------- Titles / ã‚¿ã‚¤ãƒˆãƒ« ----------
    fig.suptitle(f"ğŸŒ AI Meaning Map â€” {lang_label}", fontsize=15, color=title_color, weight="bold")
    subtitle = f"è³ªå•ï¼š{question}" if lang == "ja" else f"Question: {question}"
    fig.text(0.5, 0.95, subtitle, ha="center", color="lightgray")

    plt.tight_layout(pad=2)
    plt.show()
    # plt.savefig(f"figure_{lang}.png", dpi=300, bbox_inches='tight')  # ä¿å­˜ã—ãŸã„å ´åˆã“ã“ã‚’æœ‰åŠ¹åŒ–


# ==============================================================
# ğŸš€ 3. Main: Input Once â†’ Dual Output / è³ªå•1ã¤ã§2è¨€èªå‡ºåŠ›
# ==============================================================
question_input = "é­‚ã¨ã¯ä½•ã‹ï¼Ÿ30æ–‡å­—ä»¥å†…ã§ç­”ãˆã¦ãã ã•ã„ã€‚"

# ---------- Auto Translation / è‡ªå‹•ç¿»è¨³ ----------
translation_prompt = f"Translate this question into natural English: {question_input}"
translation_res = client.chat.completions.create(
    model="gpt-4o",
    messages=[{"role": "user", "content": translation_prompt}],
)
question_en = translation_res.choices[0].message.content.strip()

# ---------- Generate Both Figures / ä¸¡è¨€èªã®å›³ã‚’ç”Ÿæˆ ----------
generate_semantic_map(question_input, lang="ja")
generate_semantic_map(question_en, lang="en")
